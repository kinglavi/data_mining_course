{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xgndsU5h826K",
        "pycharm": {}
      },
      "source": "# Advanced Topics in Data Mining and Knowledge Discovery \n## Assignment 2 \nYelp is a company that  develops, hosts and markets the Yelp.com website and the Yelp mobile app, which publish crowd-sourced reviews about businesses. It also operates an online reservation service called Yelp Reservations. [Wikipedia](https://en.wikipedia.org/wiki/Yelp)\n\nIn this assignment you will classifying reviews into 3 categories: restaurants, beauty and shopping. The reviews we will be using are from the Kaggle Yelp reviews dataset.\n\nThe columns are as follows:\n* review_id  - a unique id for each review.\n* user_id - a unique id for each user.\n* business_id - a unique id for each business.\n* review_date - the date the review was published.\n* **review_text** - the review itself. \n* **business_category** - the category the review belong to, either **restaurant**, **beauty** or **shopping**.\n\n## Questions \n\n### Text Data Cleaning and Preprocessing\n\nYou\u0027re given the following text:\n\n\"Eugene loves all animals, but especially cats, he loves cats so much that he has 8 of them. His cats surely love him back, but you never know, as cats are independent creatures.\"\n\n You\u0027re using either tf–idf or Count vectorization techique for text representation.\n\n1. Given that \"cat\" is one of your features, what is the count of \"cat\" in this sentence?"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zFLotEX_9Ncr",
        "pycharm": {}
      },
      "source": "Without using lemmatize preprocess the count of cat is 0."
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WFQ1HfzF9Q63",
        "pycharm": {}
      },
      "source": "2. What can you do to the text so cat and cats will be considered the same? When is it important to do so?"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bxJ28g-79bdp",
        "pycharm": {}
      },
      "source": "I need to run lemmatisation algorithm on the text that will group similiar meaning words to the same groups."
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cd6BI-6W9ehn",
        "pycharm": {}
      },
      "source": "3. What other cleaning operations are important when working with text and why? "
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZlIlU7iT9gyn",
        "pycharm": {}
      },
      "source": "Important cleaning operations when wroking on text are:  \n1. lemmarisartion ( like mentioned in the last question)\n2. Remove punctuation and very common words that have little meaning, such as ‘the’, ‘and’, etc. All the stop words. This step is important because we dont want those words get high score ( become important paet of the sentence \n3. Transform all words to lower case. Will make lemmarizartion easier.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z9AE9kq99jKO",
        "pycharm": {}
      },
      "source": "# CODE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XyNotfKY73jK",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": "# Imports\nimport pandas as pd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VQTXWno39vid",
        "pycharm": {}
      },
      "outputs": [],
      "source": "# Data Loading:\ndf \u003d pd.read_csv(\u0027https://raw.githubusercontent.com/m-braverman/ta_dm_course_data/master/train3.csv\u0027)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cg53FDKY96PD",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": "4. Prepare the text for the classifier."
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bFc2wzVx-tbw",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": "import nltk\nimport string\nimport re\nfrom copy import deepcopy\nfrom nltk.tokenize import  word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# nltk.download() - You must download nltk for using \nstopwords \u003d set(nltk.corpus.stopwords.words(\u0027english\u0027) + [\u0027reuter\u0027, \u0027\\x03\u0027])\ntext_column \u003d \u0027review_text\u0027\nlemmatizer \u003d WordNetLemmatizer()\ntable \u003d str.maketrans(\u0027\u0027, \u0027\u0027, string.punctuation)\n\ndef pre_process(row, column_name):\n    text_column \u003d deepcopy(row[column_name])\n    \n    # Remove punctuation\n    text_column \u003d text_column.translate(table)\n    \n    # Replace numbers wih \u0027num\u0027\n    text_column \u003d re.sub(r\u0027\\d+\u0027, \u0027num\u0027, text_column)\n    \n    # Tokenize\n    tokenized_row \u003d word_tokenize(text_column)\n    \n    # Lemmatize + remove stop words + lower\n    new_array_of_words \u003d []\n    for word in tokenized_row:\n        word \u003d word.lower()\n        if word not in stopwords:\n            new_array_of_words.append(lemmatizer.lemmatize(word))\n    \n    text_column \u003d \" \".join(new_array_of_words)\n        \n    return text_column\n\ndf[f\"final_{text_column}\"] \u003d df.apply(lambda row: pre_process(row, text_column), axis\u003d1)\n\n# Convert to feature vector\nfeature_extraction \u003d TfidfVectorizer()\nX \u003d feature_extraction.fit_transform(df[f\"final_{text_column}\"].values)\n\ndf\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pOAL1px8--IR",
        "pycharm": {}
      },
      "source": "5. Split the data into train and validation sets."
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "POkc09mq-_1Z",
        "pycharm": {}
      },
      "outputs": [],
      "source": "\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n\n\ntrain, validation \u003d train_test_split(df, test_size\u003d0.3)\nmsk \u003d np.random.rand(len(df)) \u003c 0.7\n\nX_train \u003d X[msk]\ny_train \u003d df[\u0027business_category\u0027][msk]\n\nX_validation \u003d X[~msk]\ny_validation \u003d df[\u0027business_category\u0027][~msk]\n\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Dza8yhIQ-HYp",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": "6. Create and train the a classifier of your choosing:"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "s9mSjHy0-IEX",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": "\n\n# train classifier\nfrom sklearn.naive_bayes import MultinomialNB\nclf \u003d MultinomialNB().fit(X_train, y_train)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AOdp1Unj-O89",
        "pycharm": {}
      },
      "source": "7. Predict on the validation set you set aside previously:"
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "T5bRbkEq-PX7",
        "pycharm": {}
      },
      "outputs": [],
      "source": "\npred \u003d clf.predict(X_validation)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "twzb88M3-S6u",
        "pycharm": {}
      },
      "source": "8. Calculate and display the accuracy, precision, recall and F1 score on the validation set:"
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "66Xb2nS4-cuM",
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy is - 79.51959544879898%\n",
            "F1 score is - 0.7366708072629126\n",
            "Confusion Matrix is - \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\u003cdiv\u003e\n",
              "\u003cstyle scoped\u003e\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\u003c/style\u003e\n",
              "\u003ctable border\u003d\"1\" class\u003d\"dataframe\"\u003e\n",
              "  \u003cthead\u003e\n",
              "    \u003ctr style\u003d\"text-align: right;\"\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "      \u003cth\u003e0\u003c/th\u003e\n",
              "      \u003cth\u003e1\u003c/th\u003e\n",
              "      \u003cth\u003e2\u003c/th\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/thead\u003e\n",
              "  \u003ctbody\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e0\u003c/th\u003e\n",
              "      \u003ctd\u003e195\u003c/td\u003e\n",
              "      \u003ctd\u003e27\u003c/td\u003e\n",
              "      \u003ctd\u003e4\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e1\u003c/th\u003e\n",
              "      \u003ctd\u003e2\u003c/td\u003e\n",
              "      \u003ctd\u003e363\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e2\u003c/th\u003e\n",
              "      \u003ctd\u003e52\u003c/td\u003e\n",
              "      \u003ctd\u003e77\u003c/td\u003e\n",
              "      \u003ctd\u003e71\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/tbody\u003e\n",
              "\u003c/table\u003e\n",
              "\u003c/div\u003e"
            ],
            "text/plain": [
              "     0    1   2\n",
              "0  195   27   4\n",
              "1    2  363   0\n",
              "2   52   77  71"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": "from sklearn import metrics\nfrom sklearn.metrics import f1_score\n\nconfusion_matrix \u003d metrics.confusion_matrix(y_validation, pred)\nf1 \u003d f1_score(y_validation, pred, average\u003d\"macro\")\n\nprint(f\"Accuracy is - {np.mean(pred \u003d\u003d y_validation) * 100}%\")\nprint(f\"F1 score is - {f1}\")\nprint(\"Confusion Matrix is - \")\npd.DataFrame(confusion_matrix)\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GlUyAjHCrrWG",
        "pycharm": {}
      },
      "source": "9. Why do we use validation?"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KhoBg0Ljrx50",
        "pycharm": {}
      },
      "source": "We use validation because we need to test our model on data that was not in the train to get our model performance. If we will test our model on trainned data than the results will be too good (overfitted) and we won\u0027t know our model performance."
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rHyzC8LA_XF7",
        "pycharm": {}
      },
      "source": "## LIME\nLIME is used to explain what machine learning classifiers (or models) are doing.\n\nIn this part you\u0027ll be using lime to gain a deeper understaning of *WHY* the classifier decided to classify a review as a particular category. "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JlTuqYTh_Xju",
        "pycharm": {}
      },
      "outputs": [],
      "source": "! pip install lime"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BycgUQ9v_esP",
        "pycharm": {}
      },
      "source": "10. Create an LIME explainer:"
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YchAebHF_fVw",
        "pycharm": {}
      },
      "outputs": [],
      "source": "\nfrom sklearn.pipeline import make_pipeline\nfrom random import sample\n\n# c \u003d make_pipeline(feature_extraction, clf)\n# print(c.predict_proba([validation[f\"final_{text_column}\"]]))\nclass_names \u003d [\u0027Beauty\u0027, \u0027Restaurant\u0027,\u0027Shopping\u0027]\nfrom lime.lime_text import LimeTextExplainer\nexplainer \u003d LimeTextExplainer(class_names\u003dclass_names)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dNRfw7hTAWCm",
        "pycharm": {}
      },
      "source": "11. Explain using the LIME explainer the reviews in the generated indices (run the random generator once). Display the results in this notebook, the explanation should be present for all classes."
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "aNfd1ivaCW0g",
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document id: 72\n",
            "Probability(Beauty) \u003d 0.0016778360183894163\n",
            "Probability(Resturant) \u003d 0.9972963655636207\n",
            "Probability(Shopping) \u003d 0.0010257984179918363\n",
            "True class: Restaurant\n",
            "[(\u0027ordered\u0027, 0.01006996042832716), (\u0027pasta\u0027, 0.00844659031359341), (\u0027meal\u0027, 0.008101461552225232), (\u0027beef\u0027, 0.007969118078242661), (\u0027menu\u0027, 0.0076294100923698805), (\u0027terroni\u0027, -0.006585050388098162)]\n",
            "Document id: 134\n",
            "Probability(Beauty) \u003d 0.974411137263074\n",
            "Probability(Resturant) \u003d 0.022435006412692738\n",
            "Probability(Shopping) \u003d 0.003153856324238081\n",
            "True class: Beauty\n",
            "[(\u0027spa\u0027, -0.045087946827372785), (\u0027treatment\u0027, -0.03704682727963171), (\u0027appointment\u0027, -0.030080710348156334), (\u0027massage\u0027, -0.028154534987072915), (\u0027facility\u0027, -0.02147455329709962), (\u0027room\u0027, -0.020320916247461168)]\n",
            "Document id: 65\n",
            "Probability(Beauty) \u003d 0.9024222859258673\n",
            "Probability(Resturant) \u003d 0.08766692978168626\n",
            "Probability(Shopping) \u003d 0.00991078429245204\n",
            "True class: Beauty\n",
            "[(\u0027pool\u0027, -0.09074446445045903), (\u0027tower\u0027, -0.038811260935328766), (\u0027room\u0027, -0.03467879635779383), (\u0027shower\u0027, -0.027676472622722253), (\u0027mgm\u0027, -0.02687995603383383), (\u0027bedroom\u0027, -0.021843273007699428)]\n"
          ]
        }
      ],
      "source": "# Random index generator:\nsamples \u003d sample(range(1,200), 3)\n\nc \u003d make_pipeline(feature_extraction,clf)\n\nfor random_index in samples:\n    random_variable \u003d list(validation[\"final_review_text\"])[random_index]\n    exp \u003d explainer.explain_instance(random_variable, c.predict_proba, num_features\u003d6)\n    probabilities \u003d c.predict_proba([random_variable])\n    print(\u0027Document id: %d\u0027 % random_index)\n    print(\u0027Probability(Beauty) \u003d\u0027, probabilities[0,0])\n    print(\u0027Probability(Resturant) \u003d\u0027, probabilities[0,1])\n    print(\u0027Probability(Shopping) \u003d\u0027, probabilities[0,2])\n    print(\u0027True class: %s\u0027 % list(validation[\"business_category\"])[random_index])\n\n    print(exp.as_list())"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ST_Assignment2.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}