{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c9QlID0cn3XY",
    "pycharm": {}
   },
   "source": [
    "# Advanced Topics in Data Mining and Knowledge Discovery \n",
    "## Word2Vec\n",
    "Word2vec is a group of related models that are used to produce word embeddings. These models are shallow, two-layer neural networks that are trained to reconstruct linguistic contexts of words. Word2vec takes as its input a large corpus of text and produces a vector space, typically of several hundred dimensions, with each unique word in the corpus being assigned a corresponding vector in the space. Word vectors are positioned in the vector space such that words that share common contexts in the corpus are located in close proximity to one another in the space. [Wikipedia](https://en.wikipedia.org/wiki/Word2vec)\n",
    "\n",
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bST4DVh-uEW-",
    "pycharm": {}
   },
   "source": [
    "1. What are word embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "odb2g8RWn7hx",
    "pycharm": {}
   },
   "source": [
    "Word embedding is a vector representing a particular word. The vecotr is capiable to capture context of a word in a document, semnatic and synthatic similarity and relation with other words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "94qoRwwFn8nk",
    "pycharm": {}
   },
   "source": [
    "2. Propose a way to create sentence (or full review) embeddings out of word embeddings. What will happen if you use your proposed embeddings on very long texts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KZyxL6J9oBW4",
    "pycharm": {}
   },
   "source": [
    "Make an average of all the word embeddings in the sentence will give us the sentence embedding. If i will use this approach on very long text than the sentence embedding will be less accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ys8YVaLfoE5n",
    "pycharm": {}
   },
   "source": [
    "3. What are the advantages of using embedding as opposed to other vector representations (counter vectorization, tf-idf)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QALzmAgNoJdr",
    "pycharm": {}
   },
   "source": [
    "The advantages of using embedding over other vector representations are -  \n",
    "1. Word embedding vector is multi dimentional vector that capture a word relationship to other words in contrast of others methods that can't capture the relation between words.\n",
    "2. Word embedding can be trainned on large external data.\n",
    "3. Can be applied to each word and not the whole document.\n",
    "4. Ideal for problems involving single word such as a word translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LgolQsJzoMCb",
    "pycharm": {}
   },
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-i5J5W6aoJDx",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# imports - add additional imports here\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n7qq_EDAnytk",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/m-braverman/ta_dm_course_data/master/train3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "08pyl3Fxoi2P",
    "pycharm": {}
   },
   "source": [
    "4. a. Explain the following Word2Vec parameters:\n",
    "        * min_count\n",
    "        * size\n",
    "        * window\n",
    "    b. Prepare you data for the word2vec model.\n",
    "    \n",
    "    c. Create a word2vec model using Gensim, what vector size will you choose? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NEF6HYDAoy_u",
    "pycharm": {}
   },
   "source": [
    "4.a.  \n",
    "min count - The minimum number of word frequency that will get into the calculation. Ignores all words with total frequency lower than this.  \n",
    "size - Number of dimensions of the word vector.  \n",
    "window - Maximum distance between the current and predicted word within a sentence.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XHrVt5vXobnj",
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [first, place, tried, toronto, spa-hopping, pr...\n",
       "3       [value, world, one, messed, places, earth, ima...\n",
       "4       [live, num, num, miles, family, friends, ea, g...\n",
       "5       [awful, experience, dealing, sales, n't, even,...\n",
       "6       [lavo, become, go-to, place, bouncing, back, s...\n",
       "8       [came, num\\/num, visiting, tattoo, places, str...\n",
       "9       [one, irritating, inevitabilities, living, val...\n",
       "10      [horrible, here, 's, letter, num, characters, ...\n",
       "12      [tall, drink, brunette, bugs, bunny, special, ...\n",
       "15      [num.num, stars, 've, tried, zak, 's, chocolat...\n",
       "16      [planned, vegas, buffets, num, tips, buddies, ...\n",
       "18      [start, dreadful, seriously, thee, worst, gues...\n",
       "20      [woke, one, morning, went, take, photo, my, do...\n",
       "21      [say, minus, num, could, go, pages, absolute, ...\n",
       "22      [review, 'ritche, bridal, super, sale, happens...\n",
       "23      [hospitality, amazing, really, memorable, expe...\n",
       "24      [pittsburgh, area, it, 's, important, take, ti...\n",
       "25      [sin, city, ..., city, bad, things, n't, count...\n",
       "28      [email, sent, owner, never, received, reply, t...\n",
       "29      [tapas, spanish, equivalent, chinese, dim, sum...\n",
       "30      [welcome, noodles, where, asian, food, expensi...\n",
       "31      [recently, saw, karla, lambert, studio, charme...\n",
       "32      [disappointing, thanksgiving, expecting, first...\n",
       "34      [follows, experience, bid, re-bath, num, day, ...\n",
       "36      [employees, treat, customers, like, garbage, u...\n",
       "37      [went, store, purchased, sofa, chaise, able, p...\n",
       "39      ['ve, stayed, quite, times, always, pleased, f...\n",
       "40      [jd, invades, az, day, num, rokerij, pronounce...\n",
       "41      [should, start, saying, love, spa, vegas, old,...\n",
       "43      [heard, much, place, fashion, show, location, ...\n",
       "                              ...                        \n",
       "2589    [stayed, last, year, never, got, around, writi...\n",
       "2590    [click, num-star, rating, review, read, ``, wo...\n",
       "2592    [location, may, closed, ..., good, lasted, ......\n",
       "2593    [update, review, one, last, time, much, want, ...\n",
       "2594    [came, as, group, num, people, friend, 's, bir...\n",
       "2595    [usually, n't, review, places, 've, 'm, lazy, ...\n",
       "2596    [stayed, num, nights, could, n't, wait, check,...\n",
       "2597    [num, stars, come, partaking, grand, opening, ...\n",
       "2598    [first, time, walked, store, think, num-numth,...\n",
       "2599    [love, concept, behind, joe, fresh, love, idea...\n",
       "2601    [would, num, stars, possible, bought, macbook,...\n",
       "2602    [update, delmonico, \\/, emeril, 's, staff, rea...\n",
       "2603    [kamiya, 's, quick, tl, dr, last, review, spok...\n",
       "2604    [ps, long, review, worth, best, decision, made...\n",
       "2605    [would, give, zero, stars, could, some, absolu...\n",
       "2606    [let, preface, review, cafe, stating, good, th...\n",
       "2607    [first, time, check, previous, reviews, photos...\n",
       "2608    [harris, teeter, hop, skip, jump, my, house, '...\n",
       "2609    [wife, stayed, num\\/num-num\\/num, could, use, ...\n",
       "2611    [stepped, shoes, past, guests, dinner, parties...\n",
       "2614    [tell, understand, many, negative, reviews, or...\n",
       "2616    [love, dense, walkable, old, toronto, neighbor...\n",
       "2617    [family, went, kitchen, num, week, tuesday, af...\n",
       "2618    [counter, top, installers, literally, left, nu...\n",
       "2620    [stayed, num, years, ago, would, easily, given...\n",
       "2621    [oh, holy, crap, honest, god, never, ever, eve...\n",
       "2622    [*deep, sigh*, would, love, give, place, num, ...\n",
       "2624    [probably, n't, come, 're, hangry, want, food,...\n",
       "2625    [visited, location, several, times, years, usi...\n",
       "2626    [melting, pot, please, allow, summarize, exper...\n",
       "Name: final_review_text, Length: 1824, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question number 4.b.\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from copy import deepcopy\n",
    "from nltk.tokenize import  word_tokenize, sent_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# nltk.download() - You must download nltk for using \n",
    "stopwords = set(nltk.corpus.stopwords.words('english') + ['reuter', '\\x03'])\n",
    "text_column = 'review_text'\n",
    "\n",
    "def pre_process(row, column_name):\n",
    "    text_column = deepcopy(row[column_name])\n",
    "\n",
    "    # Replace numbers wih 'num'\n",
    "    text_column = re.sub(r'\\d+', 'num', text_column)\n",
    "\n",
    "    # Tokenize\n",
    "    tokenized_row = word_tokenize(text_column.lower())\n",
    "\n",
    "    # remove stop words + lower + remove punctuation\n",
    "    for word in tokenized_row:\n",
    "        if word in stopwords or word in string.punctuation:\n",
    "            tokenized_row.remove(word)\n",
    "\n",
    "    return tokenized_row\n",
    "\n",
    "\n",
    "df[f\"final_{text_column}\"] = df.apply(lambda row: pre_process(row, text_column), axis=1)\n",
    "\n",
    "# Split to train and validation\n",
    "\n",
    "X = df[f\"final_{text_column}\"]\n",
    "train, validation = train_test_split(df, test_size=0.3)\n",
    "msk = np.random.rand(len(df)) < 0.7\n",
    "\n",
    "X_train = X[msk]\n",
    "y_train = df['business_category'][msk]\n",
    "\n",
    "X_validation = X[~msk]\n",
    "y_validation = df['business_category'][~msk]\n",
    "\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Question 4.c.\n",
    "model = gensim.models.Word2Vec(X_train,min_count=5,size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choosed size=200 because i checked the accuracy of the model for different sizes (number of dimensions) and i discovered that 200 is big enough to get good accuracy and not overrfit the trainning. Also calculate time was not too long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V70BiX0go6yH",
    "pycharm": {}
   },
   "source": [
    "5. What is the models vocabulary size? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JgWuIbSNo841",
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model vocabulary size is - 10561\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model vocabulary size is - {len(model.wv.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w_2L-mw3pAYU",
    "pycharm": {}
   },
   "source": [
    "6. a. Display the 10 most similar words to 'good' according to the Word2Vec model.\n",
    "\n",
    "    b. Explain why 'bad'/'terrible' are similar to 'good' according to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dveFnrU8pCh5",
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decent', 0.8184503316879272),\n",
       " ('great', 0.7816325426101685),\n",
       " ('impressed', 0.7194135785102844),\n",
       " ('bad', 0.7181156873703003),\n",
       " ('much', 0.7090676426887512),\n",
       " ('disappointing', 0.705264687538147),\n",
       " ('forgettable', 0.6867215633392334),\n",
       " ('tasty', 0.6860816478729248),\n",
       " ('big', 0.6811453104019165),\n",
       " ('amazing', 0.6783066987991333)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 6.a - \n",
    "model.wv.most_similar('good')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "--knh9M0pEX0",
    "pycharm": {}
   },
   "source": [
    "Answer to 6.b -  \n",
    "The words 'bad'/'terrible' are similiar to 'good' because all of them are adjectives that usally exists in the same location/context in the sentence (between similar other words). The Word2Vec algorithm depend on the context of a world in the sentence and that why all of those adjactives usally exists in the same context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MR9sBLNIp1st",
    "pycharm": {}
   },
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pFz-3xYcp9WS",
    "pycharm": {}
   },
   "source": [
    "7. Create review embeddings using the method you suggested in question 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J0UU_stNp35i",
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [-0.32588437, 0.1845494, 0.20753913, 0.0462646...\n",
       "3       [-0.369014, 0.23160389, 0.19598591, -0.0051019...\n",
       "4       [-0.35817385, 0.24639024, 0.24574226, 0.112439...\n",
       "5       [-0.31849933, 0.24133524, 0.22826841, 0.119337...\n",
       "6       [-0.25779817, 0.1596853, 0.14181164, 0.0307057...\n",
       "8       [-0.32832667, 0.19891585, 0.19202474, 0.125309...\n",
       "9       [-0.34537798, 0.20179005, 0.1696644, -0.020736...\n",
       "10      [-0.39839554, 0.27014935, 0.24044673, 0.077784...\n",
       "12      [-0.28762263, 0.13525726, 0.13131414, 0.072323...\n",
       "15      [-0.3047567, 0.15302491, 0.16422091, 0.0056613...\n",
       "16      [-0.32582533, 0.16393247, 0.15367512, 0.056921...\n",
       "18      [-0.4025262, 0.2358636, 0.23800135, 0.11219228...\n",
       "20      [-0.3940325, 0.20872073, 0.22691229, 0.0368339...\n",
       "21      [-0.28505367, 0.16458203, 0.18012623, -0.00957...\n",
       "22      [-0.3037446, 0.18124746, 0.19464967, 0.0445338...\n",
       "23      [-0.26883644, 0.17279707, 0.14958753, -0.02848...\n",
       "24      [-0.14443347, 0.1389643, 0.09262905, 0.0020757...\n",
       "25      [-0.29126862, 0.19898145, 0.1566891, -0.137247...\n",
       "28      [-0.2883242, 0.1856215, 0.24872842, 0.21648367...\n",
       "29      [-0.19649515, 0.11519217, 0.08953803, 0.007088...\n",
       "30      [-0.20252144, 0.09493229, 0.099188134, 0.04279...\n",
       "31      [-0.27078775, 0.2817693, 0.28744534, 0.1284429...\n",
       "32      [-0.319324, 0.14029926, 0.14720617, 0.00165391...\n",
       "34      [-0.3555941, 0.15307516, 0.2016683, 0.04219858...\n",
       "36      [-0.36962196, 0.21222119, 0.21016553, 0.070944...\n",
       "37      [-0.36497596, 0.20417877, 0.2307234, 0.0894799...\n",
       "39      [-0.2513713, 0.22231907, 0.22988153, -0.003527...\n",
       "40      [-0.27287304, 0.1780998, 0.20875907, 0.0582346...\n",
       "41      [-0.24133502, 0.28474692, 0.13895167, -0.04894...\n",
       "43      [-0.29314712, 0.09689647, 0.16558513, 0.053087...\n",
       "                              ...                        \n",
       "2589    [-0.22591762, 0.25647637, 0.13003203, -0.11049...\n",
       "2590    [-0.26947215, 0.22210342, 0.2140087, 0.1339278...\n",
       "2592    [-0.4261956, 0.17644528, 0.20982105, 0.0297503...\n",
       "2593    [-0.32581633, 0.18681183, 0.22692895, 0.032327...\n",
       "2594    [-0.34474483, 0.14264494, 0.2402307, 0.0470088...\n",
       "2595    [-0.30614227, 0.2068098, 0.210634, 0.14557356,...\n",
       "2596    [-0.35556364, 0.22697528, 0.2222998, -0.014439...\n",
       "2597    [-0.24332815, 0.14493516, 0.12940381, -0.00295...\n",
       "2598    [-0.3422049, 0.19728075, 0.17197956, 0.0161217...\n",
       "2599    [-0.32024023, 0.22248071, 0.21442322, -0.02390...\n",
       "2601    [-0.36240208, 0.2534072, 0.2516318, 0.08415367...\n",
       "2602    [-0.32927972, 0.15124087, 0.1669876, 0.0414051...\n",
       "2603    [-0.130064, 0.13771392, 0.14834228, 0.15003012...\n",
       "2604    [-0.28521317, 0.19807005, 0.16761607, 0.051532...\n",
       "2605    [-0.33305895, 0.18066077, 0.18222682, 0.090399...\n",
       "2606    [-0.28786084, 0.13826697, 0.1992897, 0.1155924...\n",
       "2607    [-0.3036574, 0.24458143, 0.2189988, 0.05930886...\n",
       "2608    [-0.23934135, 0.20059134, 0.14238063, -0.04758...\n",
       "2609    [-0.37377194, 0.24346998, 0.27591345, 0.032940...\n",
       "2611    [-0.15889831, 0.17058182, 0.15108524, 0.010676...\n",
       "2614    [-0.37439942, 0.24368379, 0.2353006, 0.0656118...\n",
       "2616    [-0.2926287, 0.15352602, 0.15631366, 0.0707494...\n",
       "2617    [-0.19536717, 0.13501823, 0.16705069, 0.073202...\n",
       "2618    [-0.3286884, 0.1886891, 0.18644696, 0.04999672...\n",
       "2620    [-0.31402034, 0.20937473, 0.18909988, -0.06844...\n",
       "2621    [-0.3803652, 0.1478666, 0.17317179, 0.08058036...\n",
       "2622    [-0.27509502, 0.13972677, 0.17513181, 0.080857...\n",
       "2624    [-0.38950697, 0.19896829, 0.18965867, 0.034404...\n",
       "2625    [-0.3600371, 0.22609855, 0.19112296, -0.023799...\n",
       "2626    [-0.26917526, 0.18355149, 0.15442356, 0.009959...\n",
       "Name: final_review_text, Length: 1824, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "def calculate_sentence_embedding(tokenized_review_column, word_embed_model):\n",
    "    tokenized_review_column = deepcopy(tokenized_review_column)\n",
    "    review_word_vectors = []\n",
    "    for word in tokenized_review_column:\n",
    "        if word in word_embed_model.wv.vocab:\n",
    "            review_word_vectors.append(model.wv[word])\n",
    "\n",
    "    review_embedding = numpy.average(review_word_vectors, axis=0)\n",
    "    return review_embedding\n",
    "\n",
    "\n",
    "X_train_sentence_embedding = X_train.apply(\n",
    "    lambda row: calculate_sentence_embedding(\n",
    "        row, word_embed_model=model)\n",
    ")\n",
    "\n",
    "X_validation_sentence_embedding = X_validation.apply(\n",
    "    lambda row: calculate_sentence_embedding(\n",
    "        row, word_embed_model=model)\n",
    ")\n",
    "\n",
    "X_train_sentence_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "brtEjDZnp_Yx",
    "pycharm": {}
   },
   "source": [
    "8. Create a classifier and use it to classify the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MBb0YmZgqBQx",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "extra_tree = ExtraTreesClassifier(n_estimators=200)\n",
    "classifier = extra_tree.fit(X_train_sentence_embedding.tolist(), y_train)\n",
    "\n",
    "\n",
    "pred = classifier.predict(X_validation_sentence_embedding.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fSuSnuGeqE16",
    "pycharm": {}
   },
   "source": [
    "9. Calculate the accuracy, precision, recall and F1 score on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5DmEnht-qH69",
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is - 85.34161490683229%\n",
      "F1 score is - 0.833013770824716\n",
      "Precision score is - 0.8358895591301758\n",
      "Recall score is - 0.8319238417459321\n",
      "Confusion Matrix is - \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>344</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  193    2   33\n",
       "1   11  344    9\n",
       "2   36   27  150"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,precision_score, recall_score\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_validation, pred)\n",
    "f1 = f1_score(y_validation, pred, average=\"macro\")\n",
    "precision = precision_score(y_validation, pred, average=\"macro\")\n",
    "recall = recall_score(y_validation, pred, average=\"macro\")\n",
    "\n",
    "\n",
    "print(f\"Accuracy is - {np.mean(pred == y_validation) * 100}%\")\n",
    "print(f\"F1 score is - {f1}\")\n",
    "print(f\"Precision score is - {precision}\")\n",
    "print(f\"Recall score is - {recall}\")\n",
    "print(\"Confusion Matrix is - \")\n",
    "pd.DataFrame(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ST_Assignment3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
